html_content = """<!DOCTYPE HTML>
<html>
<head>
    <title>Unit 4 Probability Activities - Numerical Analysis - Kanna AlMansoori</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
</head>
<body class="is-preload">

    <div id="wrapper">

        <!-- Header -->
        <header id="header">
            <a href="index.html" class="logo"><strong>Kanna AlMansoori</strong> <span>MSc Artificial Intelligence E-Portfolio</span></a>
            <nav>
                <a href="#menu">Menu</a>
            </nav>
        </header>

        <!-- Menu -->
        <nav id="menu">
            <ul class="links">
                <li><a href="index.html">Home</a></li>
                <li><a href="#about">About Me</a></li>
                <li><a href="launch-module.html">Launch into Computing</a></li>
                <li><a href="induction.html">Induction Computing</a></li>
                <li><a href="ai-module.html">Understanding Artificial Intelligence</a></li>
                <li><a href="numerical-analysis.html">Numerical Analysis</a></li>
                <li><a href="project.html">Project</a></li>
                <li><a href="#contact">Contact</a></li>
            </ul>
        </nav>

        <!-- Main Content -->
        <div id="main" class="alt">

            <!-- Breadcrumb Navigation -->
            <section id="one">
                <div class="inner">
                    <p><a href="numerical-analysis.html">← Back to Numerical Analysis</a></p>
                    <header class="major">
                        <h1>Unit 4: Probability Activities</h1>
                    </header>
                    <p><strong>Title:</strong> Exploring Fundamental Probability Concepts and Distributions | <strong>Deadline:</strong> End of Unit 4 | <strong>Type:</strong> Formative | <strong>Status:</strong> ✓ Complete</p>
                </div>
            </section>

            <!-- Learning Outcomes -->
            <section id="learning-outcomes">
                <div class="inner">
                    <header class="major">
                        <h2>Learning Outcomes from This Activity</h2>
                    </header>
                    <ul>
                        <li>Systematic understanding of the key mathematical and statistical concepts and techniques which underpin mechanisms in Data Science and AI.</li>
                        <li>Apply mathematical and statistical methods in these fields to help in the decision-making process.</li>
                        <li>Critically evaluate the use of statistical analysis and the numeric interpretation of results as aids in the decision-making process.</li>
                    </ul>
                </div>
            </section>

            <!-- Task Overview -->
            <section id="task-overview">
                <div class="inner">
                    <header class="major">
                        <h2>Task Overview</h2>
                    </header>
                    
                    <p>This unit introduced foundational probability concepts through three hands-on activities: basic probability calculations with marbles, real-world applications through videos, and interactive exploration of probability distributions.</p>
                    
                    <h3>Activity Components:</h3>
                    <ol>
                        <li><strong>Activity 1: Marble Probability</strong> - Calculate probabilities for selecting colored marbles and verify they sum to 1</li>
                        <li><strong>Activity 2: Real-World Applications</strong> - Watch videos on crime prediction and sampling methods</li>
                        <li><strong>Activity 3: Probability Distributions</strong> - Explore discrete (Binomial, Poisson, Hypergeometric) and continuous (Normal, Exponential) distributions</li>
                    </ol>

                    <div class="box">
                        <h4>Key Focus:</h4>
                        <p>Understanding how probability theory forms the mathematical foundation for uncertainty in data science and AI applications.</p>
                    </div>
                </div>
            </section>

            <!-- Methodology -->
            <section id="methodology">
                <div class="inner">
                    <header class="major">
                        <h2>Methodology</h2>
                    </header>
                    
                    <h3>Activity 1: Marble Probability</h3>
                    <p>Using the Wolfram demonstration website, I calculated probabilities for a scenario with 1 red, 1 blue, and 1 yellow marble (3 total).</p>
                    <p><strong>Formula:</strong> P(event) = Number of favorable outcomes / Total possible outcomes</p>

                    <h3>Activity 2: Video Learning</h3>
                    <ul>
                        <li><strong>Crime Spotting:</strong> Explored how probability is used in predictive policing and resource allocation</li>
                        <li><strong>Sampling Methods:</strong> Learned about stratified, systematic, and cluster sampling techniques</li>
                    </ul>

                    <h3>Activity 3: Distribution Exploration</h3>
                    <p>Used interactive Jupyter notebooks to explore how changing parameters affects distribution shapes:</p>
                    
                    <h4>Discrete Distributions:</h4>
                    <ul>
                        <li><strong>Binomial:</strong> Models successes in fixed trials (parameters: n, p)</li>
                        <li><strong>Poisson:</strong> Models event counts over time (parameter: λ)</li>
                        <li><strong>Hypergeometric:</strong> Models sampling without replacement (parameters: N, k, n)</li>
                    </ul>

                    <h4>Continuous Distributions:</h4>
                    <ul>
                        <li><strong>Normal:</strong> Bell curve shape (parameters: μ mean, σ standard deviation)</li>
                        <li><strong>Exponential:</strong> Models waiting times (parameter: λ rate)</li>
                    </ul>
                </div>
            </section>

            <!-- Results -->
            <section id="results">
                <div class="inner">
                    <header class="major">
                        <h2>Results</h2>
                    </header>

                    <h3>Activity 1: Marble Probability Solutions</h3>
                    <div class="table-wrapper">
                        <table>
                            <thead>
                                <tr>
                                    <th>Question</th>
                                    <th>Calculation</th>
                                    <th>Answer</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>P(red marble)</td>
                                    <td>1/3</td>
                                    <td>0.333 or 33.33%</td>
                                </tr>
                                <tr>
                                    <td>P(blue marble)</td>
                                    <td>1/3</td>
                                    <td>0.333 or 33.33%</td>
                                </tr>
                                <tr>
                                    <td>P(yellow marble)</td>
                                    <td>1/3</td>
                                    <td>0.333 or 33.33%</td>
                                </tr>
                                <tr style="background-color: #f5f5f5;">
                                    <td><strong>Verification</strong></td>
                                    <td>1/3 + 1/3 + 1/3</td>
                                    <td><strong>1.0 ✓</strong></td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <h3>Activity 2: Key Insights</h3>
                    <div class="box">
                        <p><strong>Crime Prediction:</strong> Demonstrated how probability helps predict where crimes are likely to occur, enabling better resource allocation.</p>
                        <p><strong>Sampling Methods:</strong> Learned that different sampling techniques (stratified, systematic, cluster) affect data quality and representation.</p>
                    </div>

                    <h3>Activity 3: Distribution Characteristics</h3>
                    <div class="table-wrapper">
                        <table>
                            <thead>
                                <tr>
                                    <th>Distribution</th>
                                    <th>Type</th>
                                    <th>Common Use</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Binomial</td>
                                    <td>Discrete</td>
                                    <td>A/B testing, quality control</td>
                                </tr>
                                <tr>
                                    <td>Poisson</td>
                                    <td>Discrete</td>
                                    <td>Event counting, anomaly detection</td>
                                </tr>
                                <tr>
                                    <td>Hypergeometric</td>
                                    <td>Discrete</td>
                                    <td>Sampling without replacement</td>
                                </tr>
                                <tr>
                                    <td>Normal</td>
                                    <td>Continuous</td>
                                    <td>Most ML algorithms, test scores</td>
                                </tr>
                                <tr>
                                    <td>Exponential</td>
                                    <td>Continuous</td>
                                    <td>Time between events, survival analysis</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <div class="box">
                        <h4>Key Observations:</h4>
                        <ul>
                            <li>Normal distribution is symmetric when μ=0 and becomes wider as σ increases</li>
                            <li>Binomial distribution is symmetric when p=0.5</li>
                            <li>Poisson confidence intervals widen over time, showing accumulating uncertainty</li>
                            <li>Exponential distribution has a "memoryless" property - past doesn't affect future probability</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Analysis and Interpretation -->
            <section id="analysis">
                <div class="inner">
                    <header class="major">
                        <h2>Analysis and Key Findings</h2>
                    </header>

                    <h3>1. Why This Matters for AI and Data Science</h3>
                    <div class="box">
                        <p>Probability isn't just math—it's the language machines use to handle uncertainty. Every time a model predicts something, it's calculating probabilities. Understanding these distributions helps me:</p>
                        <ul>
                            <li>Choose the right model for the right problem</li>
                            <li>Interpret what predictions actually mean</li>
                            <li>Recognize when data doesn't fit expected patterns (anomaly detection)</li>
                            <li>Understand why balanced datasets matter in classification</li>
                        </ul>
                    </div>

                    <h3>2. Real-World Connections</h3>
                    <div class="box">
                        <p><strong>Binomial → A/B Testing:</strong> When comparing two website versions, we're counting successes (clicks/conversions) in n trials. The binomial distribution tells us if the difference is real or just luck.</p>
                        
                        <p><strong>Poisson → System Monitoring:</strong> How many errors per hour is normal? Poisson helps detect when something's wrong.</p>
                        
                        <p><strong>Normal → Everything:</strong> From test scores to measurement errors, the Central Limit Theorem explains why normal distribution appears everywhere. Most ML algorithms assume errors are normally distributed.</p>
                        
                        <p><strong>Exponential → Waiting Times:</strong> Time until next customer arrival, time until equipment fails. Its "memoryless" property means past waiting doesn't affect future waiting.</p>
                    </div>

                    <h3>3. The Sampling Insight</h3>
                    <div class="box">
                        <p>The sampling methods video hit home: <strong>bad sampling = biased model</strong>. If training data isn't representative (because of poor sampling), the model will fail in production. Stratified sampling ensures all groups are represented—crucial for fair AI systems.</p>
                    </div>

                    <h3>4. Parameter Sensitivity</h3>
                    <div class="box">
                        <p>Playing with the interactive simulations showed me how sensitive distributions are to their parameters. Small changes in λ, μ, or σ can dramatically change probabilities. This means:</p>
                        <ul>
                            <li>Accurate parameter estimation is critical</li>
                            <li>Understanding what parameters mean is essential</li>
                            <li>Wrong distribution choice leads to wrong conclusions</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Learning Outcomes -->
            <section id="learning-outcomes-achieved">
                <div class="inner">
                    <header class="major">
                        <h2>⭐ What I Learned</h2>
                    </header>
                    
                    <h3>Technical Skills:</h3>
                    <ul>
                        <li>Calculate basic probabilities and verify they sum to 1</li>
                        <li>Identify which distribution fits different scenarios</li>
                        <li>Understand what distribution parameters (μ, σ, λ, p, n) mean in practice</li>
                        <li>Recognize discrete vs continuous distributions and when to use each</li>
                    </ul>

                    <h3>Practical Understanding:</h3>
                    <ul>
                        <li><strong>Why balanced datasets matter:</strong> Binomial distribution is most predictable when p=0.5</li>
                        <li><strong>Why normal distribution is everywhere:</strong> Central Limit Theorem + many natural phenomena</li>
                        <li><strong>Why sampling matters:</strong> Poor sampling creates biased models</li>
                        <li><strong>Why parameters matter:</strong> Small changes can dramatically affect predictions</li>
                    </ul>

                    <h3>AI/ML Applications:</h3>
                    <ul>
                        <li><strong>Classification:</strong> Binomial for success/failure outcomes</li>
                        <li><strong>Anomaly Detection:</strong> Poisson for unusual event frequencies</li>
                        <li><strong>Regression:</strong> Normal distribution for error terms</li>
                        <li><strong>Survival Analysis:</strong> Exponential for time-to-event modeling</li>
                        <li><strong>Bayesian ML:</strong> Prior and posterior distributions</li>
                    </ul>
                </div>
            </section>

            <!-- Reflection -->
            <section id="reflection">
                <div class="inner">
                    <header class="major">
                        <h2>Reflection</h2>
                    </header>
                    
                    <p>This unit transformed probability from abstract math into something practical. The marble activity seemed simple—just 1/3 for each color—but it demonstrates the core axioms that every probability model must follow. When ML models output probabilities that don't sum to 1, that's a red flag.</p>
                    
                    <p>The distribution exploration was eye-opening. Seeing how the normal curve shifts with μ and widens with σ built intuition I couldn't get from formulas alone. Now when I see "standardization" in ML preprocessing, I know it's about transforming data to mean=0 and std=1 (the standard normal distribution).</p>
                    
                    <p>The crime prediction video raised important ethical questions. Yes, probability helps optimize police deployment, but it can also reinforce biases if the historical data is biased. This taught me that data scientists can't just optimize metrics—we need to think critically about how our models affect society.</p>
                    
                    <p>Understanding sampling methods was crucial. The difference between stratified and simple random sampling isn't academic—it directly affects whether my training data represents reality. A model trained on biased samples will fail in production, no matter how sophisticated the algorithm.</p>
                    
                    <p>The exponential distribution's "memoryless property" fascinated me. The fact that past waiting doesn't affect future probability seems counterintuitive but simplifies many calculations. However, it only works when there's no aging effect—equipment that wears out needs a different distribution.</p>
                    
                    <p>What really clicked: probability isn't about predicting exactly what will happen—it's about quantifying uncertainty so we can make optimal decisions. The newsvendor model showed this perfectly: even with the best decision (Q=469), we still expect 6 units understocked and 125 overstocked. That's not failure; that's optimal decision-making under uncertainty.</p>
                    
                    <p>Looking forward, these foundations will support everything in AI: Bayesian methods, probabilistic graphical models, confidence intervals, hypothesis testing, and Monte Carlo simulations all build on what I learned here. This unit wasn't just about learning distributions—it was about developing probabilistic thinking, the mindset needed to work with real-world data and build robust AI systems.</p>
                </div>
            </section>

            <!-- Navigation -->
            <section id="navigation">
                <div class="inner">
                    <ul class="actions">
                        <li><a href="data-activity3.html" class="button">← Previous: Data Activity 3</a></li>
                        <li><a href="numerical-analysis.html" class="button">Back to Module Overview</a></li>
                        <li><a href="unit4-seminar.html" class="button">Next: Unit 4 Seminar →</a></li>
                    </ul>
                </div>
            </section>

        </div>

        <!-- Footer -->
        <footer id="footer">
            <div class="inner">
                <ul class="icons">
                    <li><a href="https://github.com/KannaAlmansoori" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
                </ul>
                <ul class="copyright">
                    <li>&copy; 2025 Kanna AlMansoori</li>
                    <li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
                </ul>
            </div>
        </footer>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>
</html>"""

